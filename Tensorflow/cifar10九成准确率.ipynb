{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-839edfae-f230-4005-ad81-d2fcfcd1621c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "78414157",
    "execution_start": 1624065448507,
    "execution_millis": 12520,
    "deepnote_cell_type": "code"
   },
   "source": "import tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport tensorflow.keras.preprocessing.image as image\nimport matplotlib.pyplot as plt\nimport os\n\ndef dense_block(x, blocks, name, growth_rate = 32):\n    for i in range(blocks):\n        x = conv_block(x, growth_rate, name=name + '_block' + str(i + 1))\n    return x\n\ndef transition_block(x, reduction, name):\n    x = layers.BatchNormalization(axis=3, epsilon=1.001e-5,name=name + '_bn')(x)\n    x = layers.Activation('relu', name=name + '_relu')(x)\n    filter = x.shape[3]\n    x = layers.Conv2D(int(filter*reduction), 1,use_bias=False,name=name + '_conv')(x)\n    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n    return x\n\ndef conv_block(x, growth_rate, name):\n    x1 = layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n    x1 = layers.Activation('relu')(x1)\n    x1 = layers.Conv2D(2 * growth_rate, 1,use_bias=False, name=name + '_1_conv')(x1)\n    x1 = layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x1)\n    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n    x1 = layers.Conv2D(growth_rate, 3 ,padding='same',use_bias=False, name=name + '_2_conv')(x1)\n    x = layers.Concatenate( name=name + '_concat')([x, x1])\n    return x\n\ndef my_densenet():\n    inputs = keras.Input(shape=(32, 32, 3), name='img')\n    x = layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(inputs)\n    x = layers.BatchNormalization()(x)\n    blocks = [4,8,16]\n    x = dense_block(x, blocks[0], name='conv1',growth_rate =32)\n    x = transition_block(x, 0.5, name='pool1')\n    x = dense_block(x, blocks[1], name='conv2',growth_rate =32)\n    x = transition_block(x, 0.5, name='pool2')\n    x = dense_block(x, blocks[2], name='conv3',growth_rate =32)\n    x = transition_block(x, 0.5, name='pool3')\n    x = layers.BatchNormalization(axis=3, epsilon=1.001e-5, name='bn')(x)\n    x = layers.Activation('relu', name='relu')(x)\n\n    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n    x = layers.Dense(10, activation='softmax', name='fc1000')(x)\n\n    model = keras.Model(inputs, x, name='densenet121')\n    return model\n\ndenseNet = my_densenet()\ndenseNet.compile(optimizer=keras.optimizers.Adam(),\n                 loss=keras.losses.SparseCategoricalCrossentropy(),\n                #metrics=['accuracy'])\n                metrics=[keras.metrics.SparseCategoricalAccuracy()])\n#denseNet.summary()\n#keras.utils.plot_model(denseNet, 'my_denseNet.png', show_shapes=True)\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\ntrain_datagen = image.ImageDataGenerator(\n        rescale=1 / 255,\n        rotation_range=40,  # 角度值，0-180.表示图像随机旋转的角度范围\n        width_shift_range=0.2,  # 平移比例，下同\n        height_shift_range=0.2,\n        shear_range=0.2,  # 随机错切变换角度\n        zoom_range=0.2,  # 随即缩放比例\n        horizontal_flip=True,  # 随机将一半图像水平翻转\n        fill_mode='nearest'  # 填充新创建像素的方法\n    )\ntest_datagen = image.ImageDataGenerator(rescale=1 / 255)\nvalidation_datagen = image.ImageDataGenerator(rescale=1 / 255)\ntrain_generator = train_datagen.flow(x_train[:45000], y_train[:45000], batch_size=128)\n# train_generator = train_datagen.flow(x_train, y_train, batch_size=128)\nvalidation_generator = validation_datagen.flow(x_train[45000:], y_train[45000:], batch_size=128)\ntest_generator = test_datagen.flow(x_test, y_test, batch_size=128)\nhistory = denseNet.fit_generator(train_generator, steps_per_epoch=351, epochs=100,\n            validation_data=validation_generator, validation_steps=39, initial_epoch = 0)\nresult = denseNet.evaluate_generator(test_generator, verbose=2)\nprint(result)\n\ndef show_result(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.plot(history.history['sparse_categorical_accuracy'])\n    plt.plot(history.history['val_sparse_categorical_accuracy'])\n    plt.legend(['loss', 'val_loss', 'sparse_categorical_accuracy', 'val_sparse_categorical_accuracy'],\n                   loc='upper left')\n    plt.show()\n    print(history)\nshow_result(history)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.8/py/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\nEpoch 1/100\n  8/351 [..............................] - ETA: 54:42 - loss: 2.2969 - sparse_categorical_accuracy: 0.1465",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-3e468400-4160-4ba0-b65a-46bab6d1e287",
    "deepnote_cell_type": "code"
   },
   "source": "import tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\n\nimport time as time\nimport tensorflow.keras.preprocessing.image as image\nimport matplotlib.pyplot as plt\nimport os\n\ndef dense_block(x, blocks, name, growth_rate = 32):\n    for i in range(blocks):\n        x = conv_block(x, growth_rate, name=name + '_block' + str(i + 1))\n    return x\n\ndef transition_block(x, reduction, name):\n    x = layers.BatchNormalization(axis=3, epsilon=1.001e-5,name=name + '_bn')(x)\n    x = layers.Activation('relu', name=name + '_relu')(x)\n    filter = x.shape[3]\n    x = layers.Conv2D(int(filter*reduction), 1,use_bias=False,name=name + '_conv')(x)\n    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n    return x\n\ndef conv_block(x, growth_rate, name):\n    x1 = layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n    x1 = layers.Activation('relu')(x1)\n    x1 = layers.Conv2D(2 * growth_rate, 1,use_bias=False, name=name + '_1_conv')(x1)\n    x1 = layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x1)\n    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n    x1 = layers.Conv2D(growth_rate, 3 ,padding='same',use_bias=False, name=name + '_2_conv')(x1)\n    x = layers.Concatenate( name=name + '_concat')([x, x1])\n    return x\n\ndef my_densenet():\n    inputs = keras.Input(shape=(32, 32, 3), name='img')\n    x = layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(inputs)\n    x = layers.BatchNormalization()(x)\n    blocks = [4,8,16]\n    x = dense_block(x, blocks[0], name='conv1',growth_rate =32)\n    x = transition_block(x, 0.5, name='pool1')\n    x = dense_block(x, blocks[1], name='conv2',growth_rate =32)\n    x = transition_block(x, 0.5, name='pool2')\n    x = dense_block(x, blocks[2], name='conv3',growth_rate =32)\n    x = transition_block(x, 0.5, name='pool3')\n    x = layers.BatchNormalization(axis=3, epsilon=1.001e-5, name='bn')(x)\n    x = layers.Activation('relu', name='relu')(x)\n\n    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n    x = layers.Dense(10, activation='softmax', name='fc1000')(x)\n\n    model = keras.Model(inputs, x, name='densenet121')\n    return model\ndef my_model():\n    denseNet = my_densenet()\n\n    denseNet.compile(optimizer=keras.optimizers.Adam(),\n                 loss=keras.losses.SparseCategoricalCrossentropy(),\n                #metrics=['accuracy'])\n                metrics=[keras.metrics.SparseCategoricalAccuracy()])\n    denseNet.summary()\n    #keras.utils.plot_model(denseNet, 'my_denseNet.png', show_shapes=True)\n    return denseNet\n\ncurrent_max_loss = 9999\n\nweight_file='./weights5_2/model.h5'\n\ndef train_my_model(deep_model):\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n    train_datagen = image.ImageDataGenerator(\n        rescale=1 / 255,\n        rotation_range=40,  # 角度值，0-180.表示图像随机旋转的角度范围\n        width_shift_range=0.2,  # 平移比例，下同\n        height_shift_range=0.2,\n        shear_range=0.2,  # 随机错切变换角度\n        zoom_range=0.2,  # 随即缩放比例\n        horizontal_flip=True,  # 随机将一半图像水平翻转\n        fill_mode='nearest'  # 填充新创建像素的方法\n    )\n\n    test_datagen = image.ImageDataGenerator(rescale=1 / 255)\n\n    validation_datagen = image.ImageDataGenerator(rescale=1 / 255)\n\n    train_generator = train_datagen.flow(x_train[:45000], y_train[:45000], batch_size=128)\n    # train_generator = train_datagen.flow(x_train, y_train, batch_size=128)\n    validation_generator = validation_datagen.flow(x_train[45000:], y_train[45000:], batch_size=128)\n\n    test_generator = test_datagen.flow(x_test, y_test, batch_size=128)\n\n    begin_time = time.time()\n\n    if os.path.isfile(weight_file):\n        print('load weight')\n        deep_model.load_weights(weight_file)\n\n\n    def save_weight(epoch, logs):\n        global current_max_loss\n        if(logs['val_loss'] is not None and  logs['val_loss']< current_max_loss):\n            current_max_loss = logs['val_loss']\n            print('save_weight', epoch, current_max_loss)\n            deep_model.save_weights(weight_file)\n\n    batch_print_callback = keras.callbacks.LambdaCallback(\n        on_epoch_end=save_weight\n    )\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(patience=4, monitor='loss'),\n        batch_print_callback,\n        # keras.callbacks.ModelCheckpoint('./weights/model.h5', save_best_only=True),\n        tf.keras.callbacks.TensorBoard(log_dir='logs5_2')\n    ]\n\n    print(train_generator[0][0].shape)\n\n    history = deep_model.fit_generator(train_generator, steps_per_epoch=351, epochs=200, callbacks=callbacks,\n                                       validation_data=validation_generator, validation_steps=39, initial_epoch = 0)\n    global current_max_loss\n    if (history.history['val_loss'] is not None and history.history['val_loss'] < current_max_loss):\n        current_max_loss = history['val_loss']\n        print('save_weight', current_max_loss)\n        deep_model.save_weights(weight_file)\n\n    result = deep_model.evaluate_generator(test_generator, verbose=2)\n\n    print(result)\n    print('time', time.time() - begin_time)\n\n    def show_result(history):\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.plot(history.history['sparse_categorical_accuracy'])\n        plt.plot(history.history['val_sparse_categorical_accuracy'])\n        plt.legend(['loss', 'val_loss', 'sparse_categorical_accuracy', 'val_sparse_categorical_accuracy'],\n                   loc='upper left')\n        plt.show()\n        print(history)\n\n    show_result(history)\ndef test_module(deep_model):\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n    test_datagen = image.ImageDataGenerator(rescale=1 / 255)\n\n\n    test_generator = test_datagen.flow(x_test, y_test, batch_size=128)\n\n    begin_time = time.time()\n\n    if os.path.isfile(weight_file):\n        print('load weight')\n        deep_model.load_weights(weight_file)\n\n    result = deep_model.evaluate_generator(test_generator, verbose=2)\n\n    print(result)\n    print('time', time.time() - begin_time)\n\ndef predict_module(deep_model):\n    x_train, y_train, x_test, y_test = image_augment.get_all_train_data(False)\n\n    import numpy as np\n    if os.path.isfile(weight_file):\n        print('load weight')\n        deep_model.load_weights(weight_file)\n\n    print(y_test[0:20])\n    for i in range(20):\n        img = x_test[i][np.newaxis, :]/255\n\n        y_ = deep_model.predict(img)\n        v  = np.argmax(y_)\n        print(v, y_test[i])\n\n\n\n#my_densenet()\n#deep_model = my_model()\n#train_my_model(deep_model)\n#test_module(deep_model)\n#predict_module(deep_model)\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=26e5d5b4-a604-4f7b-aef4-7756f8127ef0' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "793f0838-76fa-4fe9-9c7c-300a14fef383",
  "deepnote_execution_queue": []
 }
}